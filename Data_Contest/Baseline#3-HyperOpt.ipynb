{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some Experiements to try out**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Feature engineering -- most important, key to get in the top 5.\n",
    "    * create features like support/oppose ratio, frequency of review and ratings, min ratings for every emp-comp pair, etc.\n",
    "    * one more imp feature, the last recorded rating/ review, and then maybe having one more feature like difference between the last rating, reviews with the average of all the previous ratings/ reviews. Now this would be of highly decisive nature to decide whether employee is leaving,\n",
    "    * adding more to that, you can calculate a gradient of the rating list of that employee for a particular company, this gradient might indicate the employee's attitude towards the company.\n",
    "    * the probability decision threshold is set to be 0.15 now, you can tune it around 0.10-0.20 and see the differnece, I would say decreasing it further might overfit the submission, so better to be on safe side\n",
    "    \n",
    "2. Other methods\n",
    "    * Trying out ensemble learning -- voting ensemble, weighted ensemble, stacking ensemble, in the respective order\n",
    "    * Hyperparameter tuning, -- the last thing you would want to try, if nothing is working out, go for it\n",
    "    * h2o.ml -- auto finetuning API, sometimes sucks, but is good for higher scale ensemble. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "# pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Imports for better visualization\n",
    "from matplotlib import rcParams\n",
    "#colorbrewer2 Dark2 qualitative color table\n",
    "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
    "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
    "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
    "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
    "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
    "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
    "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843)]\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 4)\n",
    "rcParams['figure.dpi'] = 150\n",
    "#rcParams['axes.color_cycle'] = dark2_colors\n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['font.size'] = 8\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['patch.facecolor'] = dark2_colors[0]\n",
    "rcParams['font.family'] = 'StixGeneral'\n",
    "rcParams['axes.grid'] = True\n",
    "rcParams['axes.facecolor'] = '#eeeeee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 536 ms, sys: 68.4 ms, total: 605 ms\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "ratings = pd.read_csv('./data/ratings.csv')\n",
    "remarks = pd.read_csv('./data/remarks.csv')\n",
    "remarks_support = pd.read_csv('./data/remarks_supp_opp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emp</th>\n",
       "      <th>comp</th>\n",
       "      <th>lastratingdate</th>\n",
       "      <th>left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2228</td>\n",
       "      <td>939</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>17-10-2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4349</td>\n",
       "      <td>250</td>\n",
       "      <td>jblrepyr</td>\n",
       "      <td>19-03-2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>945</td>\n",
       "      <td>134</td>\n",
       "      <td>ewpvmfbc</td>\n",
       "      <td>21-09-2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4553</td>\n",
       "      <td>164</td>\n",
       "      <td>wsmblohy</td>\n",
       "      <td>17-03-2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>941</td>\n",
       "      <td>129</td>\n",
       "      <td>ewpvmfbc</td>\n",
       "      <td>04-04-2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  emp      comp lastratingdate  left\n",
       "0  2228  939  phcvroct     17-10-2016     1\n",
       "1  4349  250  jblrepyr     19-03-2017     0\n",
       "2   945  134  ewpvmfbc     21-09-2016     0\n",
       "3  4553  164  wsmblohy     17-03-2017     0\n",
       "4   941  129  ewpvmfbc     04-04-2016     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2932\n",
       "1     594\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['left'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emp</th>\n",
       "      <th>comp</th>\n",
       "      <th>lastratingdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353</td>\n",
       "      <td>509</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>20-03-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732</td>\n",
       "      <td>22</td>\n",
       "      <td>ocsicwng</td>\n",
       "      <td>17-03-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3076</td>\n",
       "      <td>2</td>\n",
       "      <td>siexkzzo</td>\n",
       "      <td>09-01-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2199</td>\n",
       "      <td>885</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>01-10-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2145</td>\n",
       "      <td>756</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>06-02-2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  emp      comp lastratingdate\n",
       "0   353  509  bnivzbfi     20-03-2017\n",
       "1   732   22  ocsicwng     17-03-2017\n",
       "2  3076    2  siexkzzo     09-01-2017\n",
       "3  2199  885  phcvroct     01-10-2016\n",
       "4  2145  756  phcvroct     06-02-2017"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp</th>\n",
       "      <th>comp</th>\n",
       "      <th>Date</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>01-02-2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>01-02-2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>01-02-2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>01-02-2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>01-02-2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp      comp        Date  rating\n",
       "0   31  bnivzbfi  01-02-2016       4\n",
       "1   33  bnivzbfi  01-02-2016       4\n",
       "2   79  bnivzbfi  01-02-2016       4\n",
       "3   94  bnivzbfi  01-02-2016       4\n",
       "4   16  bnivzbfi  01-02-2016       2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp</th>\n",
       "      <th>comp</th>\n",
       "      <th>remarkId</th>\n",
       "      <th>txt</th>\n",
       "      <th>remarkDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>fvwadfrj</td>\n",
       "      <td>**********************************************...</td>\n",
       "      <td>20-03-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>382</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>xrrfkgap</td>\n",
       "      <td>*****************************</td>\n",
       "      <td>20-03-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>xkcrccwi</td>\n",
       "      <td>***************************</td>\n",
       "      <td>20-03-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>lohhvtmo</td>\n",
       "      <td>***************************</td>\n",
       "      <td>20-03-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>gpxxmoab</td>\n",
       "      <td>*********************************</td>\n",
       "      <td>20-03-2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp      comp  remarkId                                                txt  \\\n",
       "0  307  bnivzbfi  fvwadfrj  **********************************************...   \n",
       "1  382  bnivzbfi  xrrfkgap                      *****************************   \n",
       "2  172  bnivzbfi  xkcrccwi                        ***************************   \n",
       "3  135  bnivzbfi  lohhvtmo                        ***************************   \n",
       "4  225  bnivzbfi  gpxxmoab                  *********************************   \n",
       "\n",
       "   remarkDate  \n",
       "0  20-03-2017  \n",
       "1  20-03-2017  \n",
       "2  20-03-2017  \n",
       "3  20-03-2017  \n",
       "4  20-03-2017  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remarks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp</th>\n",
       "      <th>comp</th>\n",
       "      <th>support</th>\n",
       "      <th>oppose</th>\n",
       "      <th>remarkId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>fvwadfrj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>fvwadfrj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>fvwadfrj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>fvwadfrj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>xrrfkgap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp      comp support oppose  remarkId\n",
       "0  307  bnivzbfi    True  False  fvwadfrj\n",
       "1   36  bnivzbfi    True  False  fvwadfrj\n",
       "2  276  bnivzbfi    True  False  fvwadfrj\n",
       "3   24  bnivzbfi    True  False  fvwadfrj\n",
       "4  382  bnivzbfi    True  False  xrrfkgap"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remarks_support.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create complete training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3526, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(df):\n",
    "    print(df.shape)\n",
    "    for i in df.columns:\n",
    "        print('unique values of {} --> {} \\n'.format(i, df[i].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3526, 5)\n",
      "unique values of id --> 3526 \n",
      "\n",
      "unique values of emp --> 714 \n",
      "\n",
      "unique values of comp --> 37 \n",
      "\n",
      "unique values of lastratingdate --> 439 \n",
      "\n",
      "unique values of left --> 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_counts(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Label encoding for companies, 37 is enough! fit on train, and transform on test\n",
    "* Won't use emp -- but if its allowed to use it then no issues!\n",
    "* lastratingdate to be changed in datetime -- will use it for count, frequency of review and other time related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221232, 4)\n",
      "unique values of emp --> 788 \n",
      "\n",
      "unique values of comp --> 37 \n",
      "\n",
      "unique values of Date --> 797 \n",
      "\n",
      "unique values of rating --> 4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_counts(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82756, 5)\n",
      "unique values of emp --> 799 \n",
      "\n",
      "unique values of comp --> 36 \n",
      "\n",
      "unique values of remarkId --> 41399 \n",
      "\n",
      "unique values of txt --> 959 \n",
      "\n",
      "unique values of remarkDate --> 775 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_counts(remarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The remark text is hidden, though we can features like \"remark length\", features create from \"remark length and its support status\"\n",
    "* now again, remarkDate can be used for count, frequency and stuff of their remarks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336960, 5)\n",
      "unique values of emp --> 879 \n",
      "\n",
      "unique values of comp --> 35 \n",
      "\n",
      "unique values of support --> 2 \n",
      "\n",
      "unique values of oppose --> 2 \n",
      "\n",
      "unique values of remarkId --> 37520 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_counts(remarks_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviosuly one has given ratings several times, and probably for more that one companies during their tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(882, 4)\n",
      "unique values of id --> 882 \n",
      "\n",
      "unique values of emp --> 418 \n",
      "\n",
      "unique values of comp --> 35 \n",
      "\n",
      "unique values of lastratingdate --> 249 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_counts(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_common_test_train(var):\n",
    "    return pd.Series(test[var].unique()).isin(train[var].unique()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_common_test_train('emp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, 344 emp from train and test are common, but we cannot use emp ID as per domain restrictions! If the competition allows it then voila, we are almost at 99% accuracy,\n",
    "\n",
    "but it might be the case where the emp and company pair is different ( ideally it should be the case!)\n",
    "\n",
    "Lets check that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['comp_emp_pair'] = train['emp'].astype(str) +'_'+ train['comp'].astype(str)\n",
    "test['comp_emp_pair'] = test['emp'].astype(str) +'_'+ test['comp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_common_test_train('comp_emp_pair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "882"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['comp_emp_pair'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah our guess was right, they have preserved the testing strategy, dont have any data leak!!! \n",
    "\n",
    "As out of 800+ comp_emp pairs only 13 are common in test train, so yes, data quality is good indeed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['comp_emp_pair']\n",
    "del test['comp_emp_pair']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp</th>\n",
       "      <th>comp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>azalutpt</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ejeyobsm</th>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ewpvmfbc</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fqsozvpv</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iqdwmigj</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <th>phcvroct</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <th>phcvroct</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <th>phcvroct</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <th>phcvroct</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <th>phcvroct</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4377 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "emp comp           \n",
       "1   azalutpt      2\n",
       "    ejeyobsm    181\n",
       "    ewpvmfbc      1\n",
       "    fqsozvpv      1\n",
       "    iqdwmigj     56\n",
       "...             ...\n",
       "991 phcvroct      1\n",
       "995 phcvroct      6\n",
       "996 phcvroct     20\n",
       "997 phcvroct      1\n",
       "999 phcvroct     20\n",
       "\n",
       "[4377 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.groupby(['emp','comp'])['comp'].agg({'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yup, so many employees have served in several different companies, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For remarks we cannot just merge those two DFs on remark_id, as they are remarks from two different people on same company or matter, though we can create features out of them**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this only covers 579 emps, we might need to find a workaround to include remarks data from both DFs for remaining emp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "company_ratings_stats = ratings.groupby('comp')['rating'].agg({'rating_mean_comp':np.mean,'rating_std_comp':np.std}).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp</th>\n",
       "      <th>rating_mean_comp</th>\n",
       "      <th>rating_std_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>azalutpt</td>\n",
       "      <td>3.456522</td>\n",
       "      <td>0.861691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bhqczwkj</td>\n",
       "      <td>3.089277</td>\n",
       "      <td>0.811038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>3.236470</td>\n",
       "      <td>0.995690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bucyzegb</td>\n",
       "      <td>3.396226</td>\n",
       "      <td>0.660408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dmgwoqhz</td>\n",
       "      <td>3.475316</td>\n",
       "      <td>0.542246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ejeyobsm</td>\n",
       "      <td>2.843838</td>\n",
       "      <td>0.990282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ewpvmfbc</td>\n",
       "      <td>2.643531</td>\n",
       "      <td>0.885298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fjslutlg</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.487950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fqsozvpv</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>1.038679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iqdwmigj</td>\n",
       "      <td>2.487488</td>\n",
       "      <td>1.107501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jblrepyr</td>\n",
       "      <td>3.028743</td>\n",
       "      <td>0.860911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jnvpfmup</td>\n",
       "      <td>3.148148</td>\n",
       "      <td>0.741178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgqwnfsg</td>\n",
       "      <td>2.770209</td>\n",
       "      <td>0.931416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lydqevjo</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.028062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nmxkgvmi</td>\n",
       "      <td>3.247423</td>\n",
       "      <td>0.661925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ocsicwng</td>\n",
       "      <td>2.855814</td>\n",
       "      <td>0.966641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oecfwdaq</td>\n",
       "      <td>2.918552</td>\n",
       "      <td>0.871660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ojidyfnn</td>\n",
       "      <td>3.090314</td>\n",
       "      <td>0.912106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>oqvaqcak</td>\n",
       "      <td>2.964286</td>\n",
       "      <td>0.961563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pfmjacpm</td>\n",
       "      <td>2.684783</td>\n",
       "      <td>0.959960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>phcvroct</td>\n",
       "      <td>2.591810</td>\n",
       "      <td>1.092626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pkeebtfe</td>\n",
       "      <td>3.418848</td>\n",
       "      <td>0.776267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rcwkfavv</td>\n",
       "      <td>3.002642</td>\n",
       "      <td>0.873237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rcyiinms</td>\n",
       "      <td>3.385000</td>\n",
       "      <td>0.643262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rujnkvse</td>\n",
       "      <td>2.690715</td>\n",
       "      <td>0.997926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>siexkzzo</td>\n",
       "      <td>2.633187</td>\n",
       "      <td>0.934324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>spfcrgea</td>\n",
       "      <td>3.032680</td>\n",
       "      <td>1.155185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ugldwwzf</td>\n",
       "      <td>3.368446</td>\n",
       "      <td>0.803773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ujplihug</td>\n",
       "      <td>2.801416</td>\n",
       "      <td>0.952619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>vcqsbirc</td>\n",
       "      <td>2.880342</td>\n",
       "      <td>0.939566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>vwcdylha</td>\n",
       "      <td>2.997436</td>\n",
       "      <td>1.085171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>wsmblohy</td>\n",
       "      <td>2.763706</td>\n",
       "      <td>0.865561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>xccmgbjz</td>\n",
       "      <td>3.509695</td>\n",
       "      <td>0.695171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ydqdpmvi</td>\n",
       "      <td>2.878524</td>\n",
       "      <td>0.724472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ylpksopb</td>\n",
       "      <td>2.643324</td>\n",
       "      <td>1.017379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>yodaczsb</td>\n",
       "      <td>3.037703</td>\n",
       "      <td>0.947976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>zptfoxyq</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>0.517549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comp  rating_mean_comp  rating_std_comp\n",
       "0   azalutpt          3.456522         0.861691\n",
       "1   bhqczwkj          3.089277         0.811038\n",
       "2   bnivzbfi          3.236470         0.995690\n",
       "3   bucyzegb          3.396226         0.660408\n",
       "4   dmgwoqhz          3.475316         0.542246\n",
       "5   ejeyobsm          2.843838         0.990282\n",
       "6   ewpvmfbc          2.643531         0.885298\n",
       "7   fjslutlg          3.666667         0.487950\n",
       "8   fqsozvpv          2.777778         1.038679\n",
       "9   iqdwmigj          2.487488         1.107501\n",
       "10  jblrepyr          3.028743         0.860911\n",
       "11  jnvpfmup          3.148148         0.741178\n",
       "12  lgqwnfsg          2.770209         0.931416\n",
       "13  lydqevjo          3.333333         1.028062\n",
       "14  nmxkgvmi          3.247423         0.661925\n",
       "15  ocsicwng          2.855814         0.966641\n",
       "16  oecfwdaq          2.918552         0.871660\n",
       "17  ojidyfnn          3.090314         0.912106\n",
       "18  oqvaqcak          2.964286         0.961563\n",
       "19  pfmjacpm          2.684783         0.959960\n",
       "20  phcvroct          2.591810         1.092626\n",
       "21  pkeebtfe          3.418848         0.776267\n",
       "22  rcwkfavv          3.002642         0.873237\n",
       "23  rcyiinms          3.385000         0.643262\n",
       "24  rujnkvse          2.690715         0.997926\n",
       "25  siexkzzo          2.633187         0.934324\n",
       "26  spfcrgea          3.032680         1.155185\n",
       "27  ugldwwzf          3.368446         0.803773\n",
       "28  ujplihug          2.801416         0.952619\n",
       "29  vcqsbirc          2.880342         0.939566\n",
       "30  vwcdylha          2.997436         1.085171\n",
       "31  wsmblohy          2.763706         0.865561\n",
       "32  xccmgbjz          3.509695         0.695171\n",
       "33  ydqdpmvi          2.878524         0.724472\n",
       "34  ylpksopb          2.643324         1.017379\n",
       "35  yodaczsb          3.037703         0.947976\n",
       "36  zptfoxyq          3.625000         0.517549"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_ratings_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_last_diff_rating(x):\n",
    "#     last = x.iloc[-1]\n",
    "#     mean = x.iloc[:-1].mean()\n",
    "#     return last-mean\n",
    "\n",
    "# last_ratings_diff = ratings.groupby(['emp','comp'])['rating'].apply(get_last_diff_rating).reset_index()\n",
    "# last_ratings_diff.rename(columns={'rating':'last_rating_diff'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_pair_df = ratings.groupby(['emp','comp']).agg({'rating':'mean','Date':'count'}).reset_index(drop=False)\n",
    "ratings_pair_df.rename(columns={'rating':'avg_rating','Date':'rating_count'},inplace=True)\n",
    "\n",
    "# ratings_pair_df = ratings.groupby(['emp','comp'])['rating'].agg({'rating_mean_emp':'mean','count':'count','rating_std_emp':'std'}).reset_index(drop=False)\n",
    "# ratings_pair_df = ratings_pair_df.merge(last_ratings_diff,on=['emp','comp'],how='left')\n",
    "ratings_pair_df = ratings_pair_df.merge(company_ratings_stats,on=['comp'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp</th>\n",
       "      <th>comp</th>\n",
       "      <th>txt_len_avg</th>\n",
       "      <th>remark_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-217</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-216</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-214</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-213</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-212</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>968</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>24.375000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>969</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>970</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>211.733333</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>996</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>999</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3219 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emp      comp  txt_len_avg  remark_count\n",
       "0    -217  phcvroct   258.000000             2\n",
       "1    -216  phcvroct    25.000000             6\n",
       "2    -214  phcvroct     4.000000             2\n",
       "3    -213  phcvroct    51.000000             2\n",
       "4    -212  phcvroct     6.000000             2\n",
       "...   ...       ...          ...           ...\n",
       "3214  968  phcvroct    24.375000            16\n",
       "3215  969  phcvroct    33.500000             4\n",
       "3216  970  phcvroct   211.733333            30\n",
       "3217  996  phcvroct    83.666667            12\n",
       "3218  999  phcvroct   132.000000             8\n",
       "\n",
       "[3219 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remarks['txt_len'] = remarks['txt'].apply(lambda x:len(str(x)))\n",
    "\n",
    "remarks_pair_df = remarks.groupby(['emp','comp']).agg({'txt_len':'mean','remarkDate':'count'}).reset_index(drop=False)\n",
    "remarks_pair_df.rename(columns={'txt_len':'txt_len_avg','remarkDate':'remark_count'},inplace=True)\n",
    "remarks_pair_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_sum = lambda x:sum(x.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp         0\n",
       "comp        0\n",
       "support     1\n",
       "oppose      1\n",
       "remarkId    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remarks_support.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just drop this one NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp</th>\n",
       "      <th>comp</th>\n",
       "      <th>txt_len_avg</th>\n",
       "      <th>remark_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-217</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-216</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-214</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-213</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-212</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>968</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>24.375000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>969</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>970</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>211.733333</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>996</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>999</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3219 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emp      comp  txt_len_avg  remark_count\n",
       "0    -217  phcvroct   258.000000             2\n",
       "1    -216  phcvroct    25.000000             6\n",
       "2    -214  phcvroct     4.000000             2\n",
       "3    -213  phcvroct    51.000000             2\n",
       "4    -212  phcvroct     6.000000             2\n",
       "...   ...       ...          ...           ...\n",
       "3214  968  phcvroct    24.375000            16\n",
       "3215  969  phcvroct    33.500000             4\n",
       "3216  970  phcvroct   211.733333            30\n",
       "3217  996  phcvroct    83.666667            12\n",
       "3218  999  phcvroct   132.000000             8\n",
       "\n",
       "[3219 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remarks_support_pair_df = remarks_support.dropna().groupby(['emp','comp']).agg({'support':bool_sum,'oppose':bool_sum}).reset_index()\n",
    "remarks_pair_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**merge them with the dfs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emp</th>\n",
       "      <th>comp</th>\n",
       "      <th>lastratingdate</th>\n",
       "      <th>left</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>rating_mean_comp</th>\n",
       "      <th>rating_std_comp</th>\n",
       "      <th>txt_len_avg</th>\n",
       "      <th>remark_count</th>\n",
       "      <th>support</th>\n",
       "      <th>oppose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2228</td>\n",
       "      <td>939</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>17-10-2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.591810</td>\n",
       "      <td>1.092626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4349</td>\n",
       "      <td>250</td>\n",
       "      <td>jblrepyr</td>\n",
       "      <td>19-03-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3.767857</td>\n",
       "      <td>112</td>\n",
       "      <td>3.028743</td>\n",
       "      <td>0.860911</td>\n",
       "      <td>136.326923</td>\n",
       "      <td>104.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>945</td>\n",
       "      <td>134</td>\n",
       "      <td>ewpvmfbc</td>\n",
       "      <td>21-09-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>26</td>\n",
       "      <td>2.643531</td>\n",
       "      <td>0.885298</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4553</td>\n",
       "      <td>164</td>\n",
       "      <td>wsmblohy</td>\n",
       "      <td>17-03-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>17</td>\n",
       "      <td>2.763706</td>\n",
       "      <td>0.865561</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>941</td>\n",
       "      <td>129</td>\n",
       "      <td>ewpvmfbc</td>\n",
       "      <td>04-04-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>2.643531</td>\n",
       "      <td>0.885298</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>783</td>\n",
       "      <td>87</td>\n",
       "      <td>ocsicwng</td>\n",
       "      <td>20-03-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2.901408</td>\n",
       "      <td>71</td>\n",
       "      <td>2.855814</td>\n",
       "      <td>0.966641</td>\n",
       "      <td>74.444444</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>3655</td>\n",
       "      <td>14</td>\n",
       "      <td>jnvpfmup</td>\n",
       "      <td>17-03-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>12</td>\n",
       "      <td>3.148148</td>\n",
       "      <td>0.741178</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>1460</td>\n",
       "      <td>53</td>\n",
       "      <td>xccmgbjz</td>\n",
       "      <td>09-03-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.509695</td>\n",
       "      <td>0.695171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>842</td>\n",
       "      <td>168</td>\n",
       "      <td>ocsicwng</td>\n",
       "      <td>01-03-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>12</td>\n",
       "      <td>2.855814</td>\n",
       "      <td>0.966641</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>3236</td>\n",
       "      <td>204</td>\n",
       "      <td>siexkzzo</td>\n",
       "      <td>20-03-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>30</td>\n",
       "      <td>2.633187</td>\n",
       "      <td>0.934324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3526 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  emp      comp lastratingdate  left  avg_rating  rating_count  \\\n",
       "0     2228  939  phcvroct     17-10-2016     1    3.000000             1   \n",
       "1     4349  250  jblrepyr     19-03-2017     0    3.767857           112   \n",
       "2      945  134  ewpvmfbc     21-09-2016     0    2.923077            26   \n",
       "3     4553  164  wsmblohy     17-03-2017     0    2.411765            17   \n",
       "4      941  129  ewpvmfbc     04-04-2016     0    2.800000             5   \n",
       "...    ...  ...       ...            ...   ...         ...           ...   \n",
       "3521   783   87  ocsicwng     20-03-2017     0    2.901408            71   \n",
       "3522  3655   14  jnvpfmup     17-03-2017     0    3.083333            12   \n",
       "3523  1460   53  xccmgbjz     09-03-2017     0    3.000000             2   \n",
       "3524   842  168  ocsicwng     01-03-2017     0    3.166667            12   \n",
       "3525  3236  204  siexkzzo     20-03-2017     0    3.033333            30   \n",
       "\n",
       "      rating_mean_comp  rating_std_comp  txt_len_avg  remark_count  support  \\\n",
       "0             2.591810         1.092626          NaN           NaN      NaN   \n",
       "1             3.028743         0.860911   136.326923         104.0    233.0   \n",
       "2             2.643531         0.885298    45.800000          10.0     32.0   \n",
       "3             2.763706         0.865561    21.200000          10.0     19.0   \n",
       "4             2.643531         0.885298    75.000000           4.0      7.0   \n",
       "...                ...              ...          ...           ...      ...   \n",
       "3521          2.855814         0.966641    74.444444          18.0     22.0   \n",
       "3522          3.148148         0.741178    28.500000           4.0      4.0   \n",
       "3523          3.509695         0.695171          NaN           NaN      NaN   \n",
       "3524          2.855814         0.966641    82.333333           6.0      NaN   \n",
       "3525          2.633187         0.934324          NaN           NaN     24.0   \n",
       "\n",
       "      oppose  \n",
       "0        NaN  \n",
       "1       29.0  \n",
       "2        0.0  \n",
       "3        1.0  \n",
       "4        1.0  \n",
       "...      ...  \n",
       "3521     5.0  \n",
       "3522     1.0  \n",
       "3523     NaN  \n",
       "3524     NaN  \n",
       "3525     4.0  \n",
       "\n",
       "[3526 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new = train.merge(ratings_pair_df,on=['emp','comp'],how='left')\n",
    "train_new = train_new.merge(remarks_pair_df,on=['emp','comp'],how='left')\n",
    "train_new = train_new.merge(remarks_support_pair_df,on=['emp','comp'],how='left')\n",
    "\n",
    "train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "emp                    0\n",
       "comp                   0\n",
       "lastratingdate         0\n",
       "left                   0\n",
       "avg_rating             0\n",
       "rating_count           0\n",
       "rating_mean_comp       0\n",
       "rating_std_comp        0\n",
       "txt_len_avg         1200\n",
       "remark_count        1200\n",
       "support             1006\n",
       "oppose              1006\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These NaNs are saying something indeed, lets check out the target ration there if it helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3996023856858847"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new[train_new['support'].isna()]['left'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34833333333333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new[train_new['remark_count'].isna()]['left'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damn, the general target ration is 0.16, right now its 0.39 and 0.34, so indeed the NaN means something!, Lets impute these NaNs with -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emp</th>\n",
       "      <th>comp</th>\n",
       "      <th>lastratingdate</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>rating_mean_comp</th>\n",
       "      <th>rating_std_comp</th>\n",
       "      <th>txt_len_avg</th>\n",
       "      <th>remark_count</th>\n",
       "      <th>support</th>\n",
       "      <th>oppose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353</td>\n",
       "      <td>509</td>\n",
       "      <td>bnivzbfi</td>\n",
       "      <td>20-03-2017</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>3.236470</td>\n",
       "      <td>0.995690</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732</td>\n",
       "      <td>22</td>\n",
       "      <td>ocsicwng</td>\n",
       "      <td>17-03-2017</td>\n",
       "      <td>2.130435</td>\n",
       "      <td>69</td>\n",
       "      <td>2.855814</td>\n",
       "      <td>0.966641</td>\n",
       "      <td>43.800000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3076</td>\n",
       "      <td>2</td>\n",
       "      <td>siexkzzo</td>\n",
       "      <td>09-01-2017</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>18</td>\n",
       "      <td>2.633187</td>\n",
       "      <td>0.934324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2199</td>\n",
       "      <td>885</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>01-10-2016</td>\n",
       "      <td>2.831325</td>\n",
       "      <td>83</td>\n",
       "      <td>2.591810</td>\n",
       "      <td>1.092626</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2145</td>\n",
       "      <td>756</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>06-02-2017</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>9</td>\n",
       "      <td>2.591810</td>\n",
       "      <td>1.092626</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>4022</td>\n",
       "      <td>36</td>\n",
       "      <td>ydqdpmvi</td>\n",
       "      <td>05-10-2016</td>\n",
       "      <td>2.662162</td>\n",
       "      <td>74</td>\n",
       "      <td>2.878524</td>\n",
       "      <td>0.724472</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>3397</td>\n",
       "      <td>30</td>\n",
       "      <td>fqsozvpv</td>\n",
       "      <td>14-03-2017</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>1.038679</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1028</td>\n",
       "      <td>15</td>\n",
       "      <td>rujnkvse</td>\n",
       "      <td>30-01-2017</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.690715</td>\n",
       "      <td>0.997926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>3179</td>\n",
       "      <td>127</td>\n",
       "      <td>siexkzzo</td>\n",
       "      <td>17-03-2017</td>\n",
       "      <td>2.814815</td>\n",
       "      <td>27</td>\n",
       "      <td>2.633187</td>\n",
       "      <td>0.934324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1535</td>\n",
       "      <td>34</td>\n",
       "      <td>phcvroct</td>\n",
       "      <td>14-07-2016</td>\n",
       "      <td>2.421053</td>\n",
       "      <td>456</td>\n",
       "      <td>2.591810</td>\n",
       "      <td>1.092626</td>\n",
       "      <td>165.821053</td>\n",
       "      <td>190.0</td>\n",
       "      <td>2256.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>882 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  emp      comp lastratingdate  avg_rating  rating_count  \\\n",
       "0     353  509  bnivzbfi     20-03-2017    4.000000            43   \n",
       "1     732   22  ocsicwng     17-03-2017    2.130435            69   \n",
       "2    3076    2  siexkzzo     09-01-2017    2.444444            18   \n",
       "3    2199  885  phcvroct     01-10-2016    2.831325            83   \n",
       "4    2145  756  phcvroct     06-02-2017    2.111111             9   \n",
       "..    ...  ...       ...            ...         ...           ...   \n",
       "877  4022   36  ydqdpmvi     05-10-2016    2.662162            74   \n",
       "878  3397   30  fqsozvpv     14-03-2017    4.000000             2   \n",
       "879  1028   15  rujnkvse     30-01-2017    3.250000             4   \n",
       "880  3179  127  siexkzzo     17-03-2017    2.814815            27   \n",
       "881  1535   34  phcvroct     14-07-2016    2.421053           456   \n",
       "\n",
       "     rating_mean_comp  rating_std_comp  txt_len_avg  remark_count  support  \\\n",
       "0            3.236470         0.995690    86.000000           6.0     75.0   \n",
       "1            2.855814         0.966641    43.800000          10.0     82.0   \n",
       "2            2.633187         0.934324          NaN           NaN     19.0   \n",
       "3            2.591810         1.092626    67.500000           4.0    205.0   \n",
       "4            2.591810         1.092626    78.000000           2.0      7.0   \n",
       "..                ...              ...          ...           ...      ...   \n",
       "877          2.878524         0.724472    26.000000           2.0     47.0   \n",
       "878          2.777778         1.038679    72.000000           4.0     11.0   \n",
       "879          2.690715         0.997926          NaN           NaN      NaN   \n",
       "880          2.633187         0.934324          NaN           NaN     12.0   \n",
       "881          2.591810         1.092626   165.821053         190.0   2256.0   \n",
       "\n",
       "     oppose  \n",
       "0       2.0  \n",
       "1       6.0  \n",
       "2       8.0  \n",
       "3       7.0  \n",
       "4       0.0  \n",
       "..      ...  \n",
       "877     1.0  \n",
       "878     0.0  \n",
       "879     NaN  \n",
       "880     8.0  \n",
       "881   192.0  \n",
       "\n",
       "[882 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new = test.merge(ratings_pair_df,on=['emp','comp'],how='left')\n",
    "test_new = test_new.merge(remarks_pair_df,on=['emp','comp'],how='left')\n",
    "test_new = test_new.merge(remarks_support_pair_df,on=['emp','comp'],how='left')\n",
    "\n",
    "test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "emp                   0\n",
       "comp                  0\n",
       "lastratingdate        0\n",
       "avg_rating            0\n",
       "rating_count          0\n",
       "rating_mean_comp      0\n",
       "rating_std_comp       0\n",
       "txt_len_avg         296\n",
       "remark_count        296\n",
       "support             230\n",
       "oppose              230\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 -0.188754\n",
       "emp                 0.145559\n",
       "left                1.000000\n",
       "avg_rating         -0.058465\n",
       "rating_count       -0.044714\n",
       "rating_mean_comp   -0.128823\n",
       "rating_std_comp     0.199385\n",
       "txt_len_avg         0.015386\n",
       "remark_count        0.069445\n",
       "support             0.053945\n",
       "oppose              0.047473\n",
       "Name: left, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.corr()['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No need on LGBM\n",
    "\n",
    "# train_new.fillna(int(-9999),inplace=True)\n",
    "# test_new.fillna(int(-9999),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_new['oppose_support_ration'] = train_new['oppose']/train_new['support']\n",
    "# test_new['oppose_support_ration'] = test_new['oppose']/test_new['support']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new['flag'] = 'train'\n",
    "test_new['flag'] = 'test'\n",
    "\n",
    "merged = pd.concat([train_new,test_new]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "\n",
    "merged['comp'] = le1.fit_transform(merged['comp'])\n",
    "\n",
    "merged['emp'] = le2.fit_transform(merged['emp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(merged['emp'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DateTime Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.3 s, sys: 32.5 ms, total: 28.3 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "merged['lastratingdate'] = merged['lastratingdate'].apply(lambda x:pd.to_datetime(x))\n",
    "remarks['remarkDate'] = remarks['remarkDate'].apply(lambda x:pd.to_datetime(x))\n",
    "ratings['Date'] = ratings['Date'].apply(lambda x:pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**undo the merge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = merged[merged['flag']=='train'].reset_index(drop=True)\n",
    "test_new = merged[merged['flag']=='test'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_new['flag']\n",
    "del test_new['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new['left'] = train_new['left'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model\n",
    "\n",
    "Nothing fancy, Basic FE, processing and K-fold experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vaniall Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name=\"left\"\n",
    "id_name=\"id\"\n",
    "features_to_remove=to_drop = ['id','lastratingdate','left']\n",
    "\n",
    "features=train_new.columns.tolist()\n",
    "\n",
    "features=[ fea for fea in  features if fea not in features_to_remove  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_t, x_v, y_t, y_v = train_test_split(train_new.drop(features_to_remove,axis=1),train_new[target_name],\n",
    "                                      test_size=0.2, stratify=train[target_name], random_state=4343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=6,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(n_estimators=200,max_depth=6,learning_rate=0.1)\n",
    "# model.fit(train_new.drop(features_to_remove,axis=1),train_new[target_name])\n",
    "\n",
    "model.fit(x_t,y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(x_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>probab_to_leave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true  y_pred  probab_to_leave\n",
       "0         1       0         0.001248\n",
       "1         0       0         0.000282\n",
       "2         0       0         0.000169\n",
       "3         0       0         0.000370\n",
       "4         0       0         0.001840\n",
       "..      ...     ...              ...\n",
       "701       0       0         0.005017\n",
       "702       0       0         0.074597\n",
       "703       0       0         0.027055\n",
       "704       0       0         0.134250\n",
       "705       0       0         0.012928\n",
       "\n",
       "[706 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab_df = pd.DataFrame()\n",
    "probab_df['y_true'] = y_v.reset_index(drop=True)\n",
    "probab_df['y_pred'] = y_hat\n",
    "probab_df['probab_to_leave'] = probs[::,1]\n",
    "probab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    47.000000\n",
       "mean      0.162982\n",
       "std       0.151711\n",
       "min       0.001248\n",
       "25%       0.019004\n",
       "50%       0.108654\n",
       "75%       0.282034\n",
       "max       0.479545\n",
       "Name: probab_to_leave, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab_df[(probab_df['y_true']==1) & (probab_df['y_pred']==0)]['probab_to_leave'].describe()\n",
    "## the False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    72.000000\n",
       "mean      0.860931\n",
       "std       0.138959\n",
       "min       0.509736\n",
       "25%       0.770737\n",
       "50%       0.897459\n",
       "75%       0.988247\n",
       "max       0.999230\n",
       "Name: probab_to_leave, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab_df[(probab_df['y_true']==1) & (probab_df['y_pred']==1)]['probab_to_leave'].describe()\n",
    "## the True Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7859560067681896"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(y_v,y_hat)\n",
    "(1*cf[0][0] + 5*cf[1][1])/(1*cf[0].sum()+5*cf[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah so it seems to be getting to the baseline we have given as reference, \n",
    "\n",
    "but we haven't tuned the confidence score yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8460236886632826"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_tuned = confusion_matrix(y_v,(probs[::,1]>0.1).astype(int))\n",
    "(1*cf_tuned[0][0] + 5*cf_tuned[1][1])/(1*cf_tuned[0].sum()+5*cf_tuned[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name=\"left\"\n",
    "id_name=\"id\"\n",
    "features_to_remove=to_drop = ['id','lastratingdate','left']\n",
    "\n",
    "features=train_new.columns.tolist()\n",
    "\n",
    "features=[ fea for fea in  features if fea not in features_to_remove  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm \n",
    "import xgboost as xgb \n",
    "import catboost as cat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment_name=\"basic_model_lgbm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "try: \n",
    "    folds=pd.read_csv(\"./folds_id.csv\")\n",
    "    TRAIN=train_new.merge(folds,on=\"id\",how=\"left\")\n",
    "    TRAIN.fold.nunique() \n",
    "    \n",
    "except:\n",
    "#### you run this cell  only for the first time \n",
    "    kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=220)\n",
    "    \n",
    "    TRAIN.reset_index(drop=True,inplace=True)\n",
    "    folds=TRAIN[[\"id\"]].copy()\n",
    "    folds[\"fold\"]=0\n",
    "    for fold,(tr_indx,val_ind) in enumerate(kfold.split(folds,TRAIN[target_name])) : \n",
    "        folds.loc[val_ind,\"fold\"]=fold\n",
    "    folds.to_csv(\"./folds_id.csv\",index=False)\n",
    "    TRAIN=TRAIN.merge(folds,on=\"id\",how=\"left\")\n",
    "\n",
    "    del folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(model,train,test,params,other_params,target_name,features,metric):\n",
    "    \n",
    "    folds_num=train.fold.nunique()\n",
    "    validation=train[[id_name,\"fold\",target_name]].copy()\n",
    "    validation[\"pred_\"+target_name]=0\n",
    "    sub=test[[id_name]].copy()\n",
    "    sub[target_name]=0\n",
    "    \n",
    "    for fold in np.sort(train.fold.unique()):\n",
    "        print(\"#\"*50+\" {} \".format(fold)+\"#\"*50)\n",
    "        os.makedirs(\"model_save/lgbm/{}/{}\".format(Experiment_name,str(int(fold))), exist_ok=True)\n",
    "        X_train=train[train.fold!=fold]\n",
    "        X_val=train[train.fold==fold]\n",
    "\n",
    "        train_pred,validation_pred,test_pred=model(X_train,X_val,test,params,other_params)\n",
    "        \n",
    "        validation.loc[validation.fold==fold,\"pred_\"+target_name]=validation_pred\n",
    "        sub[target_name]+=test_pred/folds_num\n",
    "        train_score=metric(X_train[target_name],train_pred)\n",
    "        val_score=metric(X_val[target_name],validation_pred)\n",
    "        print(\"train score : {} validation score : {}\".format(round(train_score,4),round(val_score,4)))\n",
    "    \n",
    "    final_validation_score=metric(validation[target_name],validation[\"pred_\"+target_name])\n",
    "    print(\"final validation score : {}\".format(final_validation_score))\n",
    "        \n",
    "    return sub,validation,final_validation_score\n",
    "\n",
    "def lgbm_model(X_train,X_val,X_test,params,other_params):\n",
    "    \n",
    "    dtrain = lgbm.Dataset(data=X_train[features], label=X_train[target_name], feature_name=features)\n",
    "    dval = lgbm.Dataset(data=X_val[features], label=X_val[target_name], feature_name=features)\n",
    "    model = lgbm.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=other_params[\"num_boost_round\"],\n",
    "        valid_sets=(dtrain, dval),\n",
    "        early_stopping_rounds=other_params[\"early_stopping_rounds\"],\n",
    "        verbose_eval=other_params[\"verbose_eval\"],\n",
    "    )        \n",
    "    \n",
    "    best_iteration = model.best_iteration\n",
    "    train_pred=model.predict(X_train[features], num_iteration=best_iteration)\n",
    "    validation_pred=model.predict(X_val[features], num_iteration=best_iteration)\n",
    "    test_pred=model.predict(X_test[features], num_iteration=best_iteration)\n",
    "        \n",
    "    return train_pred,validation_pred,test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "## set the probab threshold here, according to your experiment\n",
    "def metric(y,y_hat,threshold=0.1):\n",
    "    cf = confusion_matrix(y,(y_hat>threshold).astype(int))\n",
    "    return (1*cf[0][0] + 5*cf[1][1])/(1*(cf[0].sum())+5*(cf[1].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_params={\"num_boost_round\":50000000,\n",
    "              \"early_stopping_rounds\":200,\n",
    "              \"verbose_eval\":1000,\n",
    "}\n",
    "\n",
    "lgbm_params = {'max_depth': 26, 'num_leaves': 80, 'min_child_samples': 200, 'scale_pos_weight': 1.0,\n",
    " 'subsample': 0.9, 'colsample_bytree': 0.6, 'lambda_2': 5.785038883822358, 'metric': 'binary_logloss',\n",
    " 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
    "\n",
    "### 0.8427651643510674 -- K-fold score with above \n",
    "\n",
    "\n",
    "# lgbm_params = {'max_depth': 19, 'num_leaves': 73, 'min_child_samples': 20, 'scale_pos_weight': 53.59603802481987, \n",
    "#  'subsample': 0.9, 'colsample_bytree': 0.7619369064645131, 'lambda_2': 4.525888999514755, \n",
    "#  'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', \n",
    "#  'learning_rate': 0.2850075764695483, 'max_bin': 100}\n",
    "# 0.8312436462216198 -- K-fold score with above, plus the last fold gave score near 0.70, means these params arent good\n",
    "\n",
    "# lgbm_params = {\n",
    "#     \"bagging_fraction\": 0.8,\n",
    "#     \"bagging_freq\": 2,\n",
    "#     \"boosting_type\": \"gbdt\",\n",
    "#     \"feature_fraction\": 0.8,\n",
    "#     \"learning_rate\": 0.01,\n",
    "#     \"max_depth\": 3,\n",
    "#     \"num_threads\": 16,\n",
    "#     \"objective\": \"binary\",\n",
    "#     \"metric\": \"binary_logloss\",\n",
    "#     \"seed\": 2020,\n",
    "# }\n",
    "# 0.8375127075567604 -- with this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 0 ##################################################\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.196066\tvalid_1's binary_logloss: 0.236846\n",
      "train score : 0.8822 validation score : 0.8494\n",
      "################################################## 1 ##################################################\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's binary_logloss: 0.211415\tvalid_1's binary_logloss: 0.249822\n",
      "train score : 0.85 validation score : 0.8493\n",
      "################################################## 2 ##################################################\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's binary_logloss: 0.106494\tvalid_1's binary_logloss: 0.21847\n",
      "train score : 0.9316 validation score : 0.8493\n",
      "################################################## 3 ##################################################\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.193565\tvalid_1's binary_logloss: 0.238532\n",
      "train score : 0.8769 validation score : 0.8425\n",
      "################################################## 4 ##################################################\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.170234\tvalid_1's binary_logloss: 0.262025\n",
      "train score : 0.8959 validation score : 0.8233\n",
      "final validation score : 0.8427651643510674\n",
      "CPU times: user 4min 35s, sys: 15.1 s, total: 4min 50s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sub,validation,score=train_function(model=lgbm_model,\n",
    "                                    train=TRAIN,\n",
    "                                    test=test_new,\n",
    "                                    params=lgbm_params,\n",
    "                                    other_params=other_params,\n",
    "                                    target_name=target_name,\n",
    "                                    features=features,\n",
    "                                    metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from skopt import gp_minimize\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_t, x_v, y_t, y_v = train_test_split(train_new.drop(features_to_remove,axis=1),train_new[target_name],\n",
    "                                      test_size=0.2, stratify=train[target_name], random_state=4343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from that dimension (`'log-uniform'` for the learning rate)\n",
    "space  = [Integer(-1, 30, name='max_depth'),\n",
    "          Integer(6, 80, name='num_leaves'),\n",
    "          Integer(20, 200, name='min_child_samples'),\n",
    "          Real(0.6, 0.9, name='subsample'),\n",
    "          Real(0.6, 0.9, name='colsample_bytree'),\n",
    "          Real(0.01,0.3,name='learning_rate'),\n",
    "          Real(0,6,name='lambda_l2'),\n",
    "          Real(1, 100, name='scale_pos_weight'),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(values):\n",
    "\n",
    "    params = {'max_depth': values[0],\n",
    "              'num_leaves': values[1],\n",
    "              'min_child_samples': values[2],\n",
    "              'scale_pos_weight': values[7],\n",
    "              'subsample': values[3],\n",
    "              'colsample_bytree': values[4],\n",
    "              'lambda_2': values[6],\n",
    "              'metric': 'binary_logloss',\n",
    "              'nthread': 8,\n",
    "              'boosting_type': 'gbdt',\n",
    "              'objective': 'binary',\n",
    "              'learning_rate': values[5],\n",
    "              'max_bin': 100,\n",
    "              #              'min_child_weight': 0,\n",
    "              #              'min_split_gain': 0,\n",
    "              #              'subsample_freq': 1,\n",
    "              }\n",
    "\n",
    "    print('\\nNext set of params.....', params)\n",
    "\n",
    "    early_stopping_rounds = 200\n",
    "    num_boost_round = 2000\n",
    "\n",
    "    # Fit model on feature_set and calculate validation AUROC\n",
    "    xgtrain = lgb.Dataset(x_t, label=y_t)\n",
    "    xgvalid = lgb.Dataset(x_v, label=y_v)\n",
    "\n",
    "    evals_results = {}\n",
    "    model_lgb = lgb.train(params, xgtrain, valid_sets=[xgtrain, xgvalid],\n",
    "                          valid_names=['train', 'valid'],\n",
    "                          evals_result=evals_results,\n",
    "                          num_boost_round=num_boost_round,\n",
    "                          early_stopping_rounds=early_stopping_rounds,\n",
    "                          verbose_eval=None, feval=None)\n",
    "\n",
    "#     auc = -roc_auc_score(y_v, model_lgb.predict(x_v))\n",
    "#     f1 = -f1_score(y_v,(model_lgb.predict(x_v)>0.5).astype(int))\n",
    "#     print(model_lgb.predict(x_v))\n",
    "#     accuracy = -accuracy_score(y_v,model_lgb.predict(x_v).argmax(axis=1))\n",
    "    score = -metric(y_v, model_lgb.predict(x_v))\n",
    "\n",
    "#     print('\\nAUROC.....',-auc,\".....iter.....\", model_lgb.current_iteration())\n",
    "#     print('\\nF1 SCORE.....',-f1,\".....iter.....\", model_lgb.current_iteration())\n",
    "    print('\\ncustom SCORE.....', -score,\n",
    "          \".....iter.....\", model_lgb.current_iteration())\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next set of params..... {'max_depth': 17, 'num_leaves': 68, 'min_child_samples': 174, 'scale_pos_weight': 6.614584754426876, 'subsample': 0.8541755216352377, 'colsample_bytree': 0.7870691090357917, 'lambda_2': 1.785207639266834, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.12147069511488297, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8384094754653131 .....iter..... 241\n",
      "\n",
      "Next set of params..... {'max_depth': 7, 'num_leaves': 41, 'min_child_samples': 166, 'scale_pos_weight': 65.16901533306853, 'subsample': 0.7439931517125172, 'colsample_bytree': 0.7178354388302489, 'lambda_2': 2.0243769625036108, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2524628414258395, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8316412859560067 .....iter..... 303\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'num_leaves': 77, 'min_child_samples': 45, 'scale_pos_weight': 68.20907348177708, 'subsample': 0.861026177507531, 'colsample_bytree': 0.7420824135821131, 'lambda_2': 3.1228648773072294, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2422641180740969, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8426395939086294 .....iter..... 72\n",
      "\n",
      "Next set of params..... {'max_depth': 21, 'num_leaves': 49, 'min_child_samples': 117, 'scale_pos_weight': 73.95489953576687, 'subsample': 0.8275846872967072, 'colsample_bytree': 0.6317722821563376, 'lambda_2': 1.11799405996056, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.14734412161053068, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8417935702199661 .....iter..... 270\n",
      "\n",
      "Next set of params..... {'max_depth': 6, 'num_leaves': 16, 'min_child_samples': 78, 'scale_pos_weight': 45.545049001211545, 'subsample': 0.644902460155105, 'colsample_bytree': 0.6666964164754763, 'lambda_2': 5.415590853176429, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.12208180452649998, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8206429780033841 .....iter..... 337\n",
      "\n",
      "Next set of params..... {'max_depth': 18, 'num_leaves': 73, 'min_child_samples': 38, 'scale_pos_weight': 75.31792798062719, 'subsample': 0.8909427203240248, 'colsample_bytree': 0.7959420107393813, 'lambda_2': 2.1489130018171503, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.0595637796894531, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8384094754653131 .....iter..... 218\n",
      "\n",
      "Next set of params..... {'max_depth': 18, 'num_leaves': 30, 'min_child_samples': 27, 'scale_pos_weight': 99.5346572001109, 'subsample': 0.7902822173872006, 'colsample_bytree': 0.8876847805873562, 'lambda_2': 3.8103532416213834, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.19930919193159238, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8375634517766497 .....iter..... 99\n",
      "\n",
      "Next set of params..... {'max_depth': 17, 'num_leaves': 37, 'min_child_samples': 105, 'scale_pos_weight': 78.05620272056501, 'subsample': 0.7870530303395605, 'colsample_bytree': 0.7014022844516675, 'lambda_2': 1.903210452415777, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.20567817345511602, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8307952622673435 .....iter..... 174\n",
      "\n",
      "Next set of params..... {'max_depth': 28, 'num_leaves': 55, 'min_child_samples': 22, 'scale_pos_weight': 51.452813295270126, 'subsample': 0.7868538286640009, 'colsample_bytree': 0.8020978892507369, 'lambda_2': 5.269160828083063, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2918640507249031, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8477157360406091 .....iter..... 31\n",
      "\n",
      "Next set of params..... {'max_depth': 1, 'num_leaves': 39, 'min_child_samples': 24, 'scale_pos_weight': 69.17745709777128, 'subsample': 0.7325132763746536, 'colsample_bytree': 0.8938760186438186, 'lambda_2': 2.8853611850169774, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.11423889455110324, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 1\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 6, 'min_child_samples': 200, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.6, 'lambda_2': 0.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.01, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8367174280879864 .....iter..... 2000\n",
      "\n",
      "Next set of params..... {'max_depth': 25, 'num_leaves': 80, 'min_child_samples': 157, 'scale_pos_weight': 1.0, 'subsample': 0.7323178883901376, 'colsample_bytree': 0.9, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.01, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8494077834179357 .....iter..... 1457\n",
      "\n",
      "Next set of params..... {'max_depth': 26, 'num_leaves': 13, 'min_child_samples': 20, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.9, 'lambda_2': 0.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.01, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8494077834179357 .....iter..... 1028\n",
      "\n",
      "Next set of params..... {'max_depth': 13, 'num_leaves': 44, 'min_child_samples': 20, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.9, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.01, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8553299492385786 .....iter..... 480\n",
      "\n",
      "Next set of params..... {'max_depth': 12, 'num_leaves': 6, 'min_child_samples': 122, 'scale_pos_weight': 1.0, 'subsample': 0.9, 'colsample_bytree': 0.6, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.01, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8367174280879864 .....iter..... 2000\n",
      "\n",
      "Next set of params..... {'max_depth': 9, 'num_leaves': 80, 'min_child_samples': 20, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.9, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.01, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8468697123519459 .....iter..... 427\n",
      "\n",
      "Next set of params..... {'max_depth': 26, 'num_leaves': 80, 'min_child_samples': 200, 'scale_pos_weight': 1.0, 'subsample': 0.9, 'colsample_bytree': 0.6, 'lambda_2': 5.785038883822358, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8663282571912013 .....iter..... 69\n",
      "\n",
      "Next set of params..... {'max_depth': 24, 'num_leaves': 32, 'min_child_samples': 20, 'scale_pos_weight': 100.0, 'subsample': 0.6, 'colsample_bytree': 0.6, 'lambda_2': 0.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.027515524398399827, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5186125211505922 .....iter..... 19\n",
      "\n",
      "Next set of params..... {'max_depth': 23, 'num_leaves': 40, 'min_child_samples': 88, 'scale_pos_weight': 2.024139212559335, 'subsample': 0.6631082851589838, 'colsample_bytree': 0.8869817738704127, 'lambda_2': 1.6020778765190293, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2961276843067552, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8544839255499154 .....iter..... 34\n",
      "\n",
      "Next set of params..... {'max_depth': 16, 'num_leaves': 65, 'min_child_samples': 37, 'scale_pos_weight': 2.645537680336053, 'subsample': 0.8413983878493436, 'colsample_bytree': 0.6801343821948966, 'lambda_2': 2.865326774983126, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2358163504105479, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8417935702199661 .....iter..... 21\n",
      "\n",
      "Next set of params..... {'max_depth': 21, 'num_leaves': 64, 'min_child_samples': 85, 'scale_pos_weight': 3.905586354350119, 'subsample': 0.6557831399335352, 'colsample_bytree': 0.732716866593302, 'lambda_2': 1.7339965568479072, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.1538543553304885, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8299492385786802 .....iter..... 66\n",
      "\n",
      "Next set of params..... {'max_depth': 18, 'num_leaves': 38, 'min_child_samples': 28, 'scale_pos_weight': 2.955912139868804, 'subsample': 0.7099485316363248, 'colsample_bytree': 0.6599152003830345, 'lambda_2': 3.963340861801516, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2471400510724552, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8468697123519459 .....iter..... 25\n",
      "\n",
      "Next set of params..... {'max_depth': 7, 'num_leaves': 68, 'min_child_samples': 20, 'scale_pos_weight': 73.74476698966569, 'subsample': 0.9, 'colsample_bytree': 0.7376330047464539, 'lambda_2': 3.599245395672127, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.01, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 46\n",
      "\n",
      "Next set of params..... {'max_depth': 29, 'num_leaves': 56, 'min_child_samples': 96, 'scale_pos_weight': 60.18203600446383, 'subsample': 0.7994588514010095, 'colsample_bytree': 0.9, 'lambda_2': 4.189715767381399, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.01, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 23\n",
      "\n",
      "Next set of params..... {'max_depth': 15, 'num_leaves': 16, 'min_child_samples': 178, 'scale_pos_weight': 39.82862666017152, 'subsample': 0.741814043233745, 'colsample_bytree': 0.6, 'lambda_2': 5.489164569815313, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.14986387776164056, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8324873096446701 .....iter..... 459\n",
      "\n",
      "Next set of params..... {'max_depth': 24, 'num_leaves': 27, 'min_child_samples': 187, 'scale_pos_weight': 7.317905860299331, 'subsample': 0.8728920589264675, 'colsample_bytree': 0.7009920646132217, 'lambda_2': 4.058902263895746, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.29923839444670297, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8350253807106599 .....iter..... 87\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 43, 'min_child_samples': 49, 'scale_pos_weight': 81.27290593782335, 'subsample': 0.75924138338665, 'colsample_bytree': 0.9, 'lambda_2': 0.4875280252539073, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.0798791405849092, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8417935702199661 .....iter..... 167\n",
      "\n",
      "Next set of params..... {'max_depth': 22, 'num_leaves': 77, 'min_child_samples': 103, 'scale_pos_weight': 68.23537249001271, 'subsample': 0.7922166148775941, 'colsample_bytree': 0.9, 'lambda_2': 1.2358214347503005, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.01, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 22\n",
      "\n",
      "Next set of params..... {'max_depth': 17, 'num_leaves': 66, 'min_child_samples': 56, 'scale_pos_weight': 81.98867190208469, 'subsample': 0.6024696916810302, 'colsample_bytree': 0.6, 'lambda_2': 4.890517027575814, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.17266378534393667, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8409475465313029 .....iter..... 122\n",
      "\n",
      "Next set of params..... {'max_depth': 17, 'num_leaves': 43, 'min_child_samples': 99, 'scale_pos_weight': 29.441749929284978, 'subsample': 0.7229978806415428, 'colsample_bytree': 0.6, 'lambda_2': 4.974502336983908, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.12995520682287734, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8350253807106599 .....iter..... 199\n",
      "\n",
      "Next set of params..... {'max_depth': 16, 'num_leaves': 57, 'min_child_samples': 59, 'scale_pos_weight': 95.49369640993865, 'subsample': 0.7798038030545731, 'colsample_bytree': 0.6290763675321278, 'lambda_2': 5.164667012816818, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2937352953767314, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8417935702199661 .....iter..... 64\n",
      "\n",
      "Next set of params..... {'max_depth': 26, 'num_leaves': 21, 'min_child_samples': 118, 'scale_pos_weight': 9.981153327887647, 'subsample': 0.6179926633143781, 'colsample_bytree': 0.6059248554176867, 'lambda_2': 3.5132470076399382, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.08294763266606428, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8299492385786802 .....iter..... 230\n",
      "\n",
      "Next set of params..... {'max_depth': 8, 'num_leaves': 57, 'min_child_samples': 70, 'scale_pos_weight': 22.559651876380165, 'subsample': 0.7077688808631991, 'colsample_bytree': 0.9, 'lambda_2': 0.2042464407206328, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.19286032232419575, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8341793570219966 .....iter..... 147\n",
      "\n",
      "Next set of params..... {'max_depth': 27, 'num_leaves': 25, 'min_child_samples': 196, 'scale_pos_weight': 37.79496158660149, 'subsample': 0.7306589130766605, 'colsample_bytree': 0.8100693592680076, 'lambda_2': 1.7447167998185495, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.22902991976412992, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8214890016920474 .....iter..... 233\n",
      "\n",
      "Next set of params..... {'max_depth': 0, 'num_leaves': 6, 'min_child_samples': 20, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.9, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.0458010836403791, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8468697123519459 .....iter..... 531\n",
      "\n",
      "Next set of params..... {'max_depth': 28, 'num_leaves': 60, 'min_child_samples': 28, 'scale_pos_weight': 100.0, 'subsample': 0.6290443952706501, 'colsample_bytree': 0.9, 'lambda_2': 2.467068643254148, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.25717219313238676, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8494077834179357 .....iter..... 33\n",
      "\n",
      "Next set of params..... {'max_depth': 26, 'num_leaves': 27, 'min_child_samples': 129, 'scale_pos_weight': 76.67053498662126, 'subsample': 0.8831927588511677, 'colsample_bytree': 0.9, 'lambda_2': 0.7699319049494073, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.07037446075783466, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 2\n",
      "\n",
      "Next set of params..... {'max_depth': 22, 'num_leaves': 70, 'min_child_samples': 77, 'scale_pos_weight': 35.035564598127884, 'subsample': 0.6688425674146085, 'colsample_bytree': 0.8015283034172371, 'lambda_2': 2.2631506395106458, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2700011497571912, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8350253807106599 .....iter..... 78\n",
      "\n",
      "Next set of params..... {'max_depth': 27, 'num_leaves': 76, 'min_child_samples': 139, 'scale_pos_weight': 55.781821721786734, 'subsample': 0.756359505825553, 'colsample_bytree': 0.8007501497717616, 'lambda_2': 0.4769349373756617, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.05217371004631567, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 2\n",
      "\n",
      "Next set of params..... {'max_depth': 24, 'num_leaves': 29, 'min_child_samples': 40, 'scale_pos_weight': 65.61227360574588, 'subsample': 0.7945048259711601, 'colsample_bytree': 0.7003899860192048, 'lambda_2': 3.2455953385986147, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.06949227705898581, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8375634517766497 .....iter..... 252\n",
      "\n",
      "Next set of params..... {'max_depth': 17, 'num_leaves': 13, 'min_child_samples': 200, 'scale_pos_weight': 100.0, 'subsample': 0.6577710331150335, 'colsample_bytree': 0.791800820818483, 'lambda_2': 3.0458427058329276, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.19002702968021232, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 1\n",
      "\n",
      "Next set of params..... {'max_depth': 16, 'num_leaves': 48, 'min_child_samples': 111, 'scale_pos_weight': 36.761289440581, 'subsample': 0.8133455525120772, 'colsample_bytree': 0.6089152351642965, 'lambda_2': 1.0074256082993984, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.22096243367638463, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8426395939086294 .....iter..... 180\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 53, 'min_child_samples': 72, 'scale_pos_weight': 71.69875387948058, 'subsample': 0.6, 'colsample_bytree': 0.6, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.18987193116768877, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8426395939086294 .....iter..... 122\n",
      "\n",
      "Next set of params..... {'max_depth': 18, 'num_leaves': 55, 'min_child_samples': 200, 'scale_pos_weight': 1.0, 'subsample': 0.8580371062307528, 'colsample_bytree': 0.6199495786946929, 'lambda_2': 3.538400631860247, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.27599504726579244, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8527918781725888 .....iter..... 87\n",
      "\n",
      "Next set of params..... {'max_depth': 27, 'num_leaves': 56, 'min_child_samples': 29, 'scale_pos_weight': 32.915202467521944, 'subsample': 0.8052216444513014, 'colsample_bytree': 0.7187767647462827, 'lambda_2': 5.277279424675733, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.02087356175506997, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8451776649746193 .....iter..... 463\n",
      "\n",
      "Next set of params..... {'max_depth': 2, 'num_leaves': 6, 'min_child_samples': 120, 'scale_pos_weight': 82.64373196612587, 'subsample': 0.9, 'colsample_bytree': 0.6, 'lambda_2': 1.66425429334456, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 1\n",
      "\n",
      "Next set of params..... {'max_depth': 3, 'num_leaves': 29, 'min_child_samples': 39, 'scale_pos_weight': 95.39625974773766, 'subsample': 0.9, 'colsample_bytree': 0.9, 'lambda_2': 5.313845833772691, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.14229155665899676, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 1\n",
      "\n",
      "Next set of params..... {'max_depth': 18, 'num_leaves': 6, 'min_child_samples': 28, 'scale_pos_weight': 18.164302891025603, 'subsample': 0.7702233445254677, 'colsample_bytree': 0.7592926882565366, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.02720310398952184, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 11\n",
      "\n",
      "Next set of params..... {'max_depth': 22, 'num_leaves': 30, 'min_child_samples': 27, 'scale_pos_weight': 42.57228063111256, 'subsample': 0.835223562518999, 'colsample_bytree': 0.7271466690840869, 'lambda_2': 5.024286324955494, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.1496434875844894, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8451776649746193 .....iter..... 98\n",
      "\n",
      "Next set of params..... {'max_depth': 9, 'num_leaves': 73, 'min_child_samples': 20, 'scale_pos_weight': 47.87228466418674, 'subsample': 0.8024394657553688, 'colsample_bytree': 0.8030005183500741, 'lambda_2': 0.4364503976472762, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.27131447039410367, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8417935702199661 .....iter..... 46\n",
      "\n",
      "Next set of params..... {'max_depth': 10, 'num_leaves': 67, 'min_child_samples': 176, 'scale_pos_weight': 50.1289414343119, 'subsample': 0.7945516750043022, 'colsample_bytree': 0.8013013102236369, 'lambda_2': 1.2933338293561827, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2711829712222832, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8375634517766497 .....iter..... 200\n",
      "\n",
      "Next set of params..... {'max_depth': 27, 'num_leaves': 67, 'min_child_samples': 38, 'scale_pos_weight': 22.16138107611565, 'subsample': 0.835349136297801, 'colsample_bytree': 0.7048178484034463, 'lambda_2': 2.704144846875651, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.1633252229519907, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8409475465313029 .....iter..... 70\n",
      "\n",
      "Next set of params..... {'max_depth': 24, 'num_leaves': 56, 'min_child_samples': 170, 'scale_pos_weight': 45.280646553280555, 'subsample': 0.8206453460542158, 'colsample_bytree': 0.6905701593399762, 'lambda_2': 0.12894571269194072, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2141995681526311, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8384094754653131 .....iter..... 279\n",
      "\n",
      "Next set of params..... {'max_depth': 15, 'num_leaves': 43, 'min_child_samples': 178, 'scale_pos_weight': 100.0, 'subsample': 0.7635984345096826, 'colsample_bytree': 0.9, 'lambda_2': 2.383986300548727, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.29353929593575684, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8375634517766497 .....iter..... 218\n",
      "\n",
      "Next set of params..... {'max_depth': 14, 'num_leaves': 19, 'min_child_samples': 187, 'scale_pos_weight': 50.237224032144994, 'subsample': 0.6711002408404612, 'colsample_bytree': 0.6, 'lambda_2': 3.9164475160024383, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.06816956555619379, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 1\n",
      "\n",
      "Next set of params..... {'max_depth': 1, 'num_leaves': 37, 'min_child_samples': 20, 'scale_pos_weight': 61.96294246302342, 'subsample': 0.7665949886486618, 'colsample_bytree': 0.6527360917095795, 'lambda_2': 2.8280859798906115, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.06918405902020161, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 1\n",
      "\n",
      "Next set of params..... {'max_depth': 22, 'num_leaves': 32, 'min_child_samples': 183, 'scale_pos_weight': 79.24042744652218, 'subsample': 0.7738552472042424, 'colsample_bytree': 0.6119025119481079, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.01, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 11\n",
      "\n",
      "Next set of params..... {'max_depth': 7, 'num_leaves': 13, 'min_child_samples': 118, 'scale_pos_weight': 78.64601887676471, 'subsample': 0.7969247699136699, 'colsample_bytree': 0.7770950114843371, 'lambda_2': 2.2196329567532547, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.20620050283031585, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8324873096446701 .....iter..... 279\n",
      "\n",
      "Next set of params..... {'max_depth': 27, 'num_leaves': 54, 'min_child_samples': 134, 'scale_pos_weight': 81.72053185790458, 'subsample': 0.6143800873862075, 'colsample_bytree': 0.6, 'lambda_2': 1.2454578505239808, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.11717382204947467, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.5033840947546532 .....iter..... 1\n",
      "\n",
      "Next set of params..... {'max_depth': 28, 'num_leaves': 76, 'min_child_samples': 32, 'scale_pos_weight': 65.75620311795652, 'subsample': 0.8381504931904732, 'colsample_bytree': 0.7275304916124045, 'lambda_2': 2.4996862765418046, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.08534708652261365, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8392554991539763 .....iter..... 118\n",
      "\n",
      "Next set of params..... {'max_depth': 13, 'num_leaves': 78, 'min_child_samples': 159, 'scale_pos_weight': 20.513996543082797, 'subsample': 0.7586588416076414, 'colsample_bytree': 0.708031101551762, 'lambda_2': 3.6065593077280287, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.19007540080458069, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8392554991539763 .....iter..... 217\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 65, 'min_child_samples': 20, 'scale_pos_weight': 26.505778372564517, 'subsample': 0.6, 'colsample_bytree': 0.8562519863869308, 'lambda_2': 1.384192230980326, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.1749098679579304, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8417935702199661 .....iter..... 44\n",
      "\n",
      "Next set of params..... {'max_depth': 21, 'num_leaves': 60, 'min_child_samples': 54, 'scale_pos_weight': 67.4786883050457, 'subsample': 0.8216172757993959, 'colsample_bytree': 0.6107151493628665, 'lambda_2': 2.7775116673314626, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.1677430358173977, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8358714043993232 .....iter..... 90\n",
      "\n",
      "Next set of params..... {'max_depth': 14, 'num_leaves': 30, 'min_child_samples': 20, 'scale_pos_weight': 66.21751151255167, 'subsample': 0.6, 'colsample_bytree': 0.624684960019477, 'lambda_2': 5.999301869979425, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8426395939086294 .....iter..... 75\n",
      "\n",
      "Next set of params..... {'max_depth': 7, 'num_leaves': 10, 'min_child_samples': 83, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.7669408258291888, 'lambda_2': 2.4351148725723566, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8485617597292724 .....iter..... 45\n",
      "\n",
      "Next set of params..... {'max_depth': 16, 'num_leaves': 29, 'min_child_samples': 131, 'scale_pos_weight': 55.31600335553471, 'subsample': 0.8226547847052375, 'colsample_bytree': 0.6, 'lambda_2': 4.09010959924021, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.17165673557785863, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8223350253807107 .....iter..... 220\n",
      "\n",
      "Next set of params..... {'max_depth': -1, 'num_leaves': 73, 'min_child_samples': 112, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.6808503171816115, 'lambda_2': 2.6957412661542737, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.12934369800360188, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8519458544839256 .....iter..... 128\n",
      "\n",
      "Next set of params..... {'max_depth': 17, 'num_leaves': 16, 'min_child_samples': 200, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.7000872597215989, 'lambda_2': 2.886835937303435, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8392554991539763 .....iter..... 56\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 69, 'min_child_samples': 24, 'scale_pos_weight': 67.16590986243504, 'subsample': 0.7344470593928399, 'colsample_bytree': 0.756930039457524, 'lambda_2': 1.1094186145910578, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.17007936964235335, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8468697123519459 .....iter..... 66\n",
      "\n",
      "Next set of params..... {'max_depth': 8, 'num_leaves': 44, 'min_child_samples': 81, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.8204025329915393, 'lambda_2': 3.872510009386821, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.1267023557256605, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8527918781725888 .....iter..... 70\n",
      "\n",
      "Next set of params..... {'max_depth': 26, 'num_leaves': 74, 'min_child_samples': 172, 'scale_pos_weight': 1.0, 'subsample': 0.7348100190346031, 'colsample_bytree': 0.6935283430979335, 'lambda_2': 4.865242520406695, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.18557625007697928, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8527918781725888 .....iter..... 103\n",
      "\n",
      "Next set of params..... {'max_depth': 19, 'num_leaves': 73, 'min_child_samples': 20, 'scale_pos_weight': 53.59603802481987, 'subsample': 0.9, 'colsample_bytree': 0.7619369064645131, 'lambda_2': 4.525888999514755, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2850075764695483, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8663282571912013 .....iter..... 24\n",
      "\n",
      "Next set of params..... {'max_depth': 25, 'num_leaves': 34, 'min_child_samples': 32, 'scale_pos_weight': 76.012465697197, 'subsample': 0.8580849802906518, 'colsample_bytree': 0.7826226301213463, 'lambda_2': 1.2746918132965792, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.08027602118773719, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8477157360406091 .....iter..... 207\n",
      "\n",
      "Next set of params..... {'max_depth': 11, 'num_leaves': 34, 'min_child_samples': 115, 'scale_pos_weight': 70.05723523014956, 'subsample': 0.7910209052137276, 'colsample_bytree': 0.6976216914436436, 'lambda_2': 5.404172550783848, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.18014058837596672, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8299492385786802 .....iter..... 244\n",
      "\n",
      "Next set of params..... {'max_depth': 14, 'num_leaves': 36, 'min_child_samples': 61, 'scale_pos_weight': 65.79673100239394, 'subsample': 0.7360241772522058, 'colsample_bytree': 0.8643308649155943, 'lambda_2': 4.735524409862018, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2692613713635147, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8350253807106599 .....iter..... 53\n",
      "\n",
      "Next set of params..... {'max_depth': -1, 'num_leaves': 20, 'min_child_samples': 191, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.8398134304430105, 'lambda_2': 5.619365222198912, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8477157360406091 .....iter..... 83\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 72, 'min_child_samples': 110, 'scale_pos_weight': 100.0, 'subsample': 0.9, 'colsample_bytree': 0.6693757830135681, 'lambda_2': 5.103806738125007, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8341793570219966 .....iter..... 138\n",
      "\n",
      "Next set of params..... {'max_depth': -1, 'num_leaves': 72, 'min_child_samples': 20, 'scale_pos_weight': 20.069967602037543, 'subsample': 0.858365857030613, 'colsample_bytree': 0.8396093804838061, 'lambda_2': 4.962309460415709, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8307952622673435 .....iter..... 23\n",
      "\n",
      "Next set of params..... {'max_depth': -1, 'num_leaves': 19, 'min_child_samples': 200, 'scale_pos_weight': 1.0, 'subsample': 0.87250604480404, 'colsample_bytree': 0.6014922735352617, 'lambda_2': 4.56856048363615, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.06726027175431942, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8578680203045685 .....iter..... 388\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 80, 'min_child_samples': 20, 'scale_pos_weight': 74.11043782337407, 'subsample': 0.7817079714368385, 'colsample_bytree': 0.8438605677628722, 'lambda_2': 2.82695432010679, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.06072127850341295, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.862098138747885 .....iter..... 142\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 54, 'min_child_samples': 37, 'scale_pos_weight': 73.85968513808682, 'subsample': 0.8041154936321773, 'colsample_bytree': 0.6610809430451766, 'lambda_2': 3.5072297671495427, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.06605855619682782, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8426395939086294 .....iter..... 183\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 35, 'min_child_samples': 129, 'scale_pos_weight': 1.0, 'subsample': 0.7293997508898495, 'colsample_bytree': 0.7576488205488012, 'lambda_2': 3.962788225492403, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.07224462357596492, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8595600676818951 .....iter..... 177\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 79, 'min_child_samples': 20, 'scale_pos_weight': 56.10200111919747, 'subsample': 0.8655674640149058, 'colsample_bytree': 0.7756757171831528, 'lambda_2': 0.014009735124920944, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.23038437156158248, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8477157360406091 .....iter..... 26\n",
      "\n",
      "Next set of params..... {'max_depth': -1, 'num_leaves': 78, 'min_child_samples': 200, 'scale_pos_weight': 28.175489109062305, 'subsample': 0.6713164364887458, 'colsample_bytree': 0.8541273266492178, 'lambda_2': 3.560691402522176, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8392554991539763 .....iter..... 239\n",
      "\n",
      "Next set of params..... {'max_depth': 25, 'num_leaves': 65, 'min_child_samples': 95, 'scale_pos_weight': 72.7370002472814, 'subsample': 0.8568129255600023, 'colsample_bytree': 0.7000618353650234, 'lambda_2': 0.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.1620028424001296, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8443316412859561 .....iter..... 178\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 79, 'min_child_samples': 20, 'scale_pos_weight': 36.718720638036885, 'subsample': 0.8046833908132829, 'colsample_bytree': 0.6572651163471602, 'lambda_2': 5.272638594263226, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.033590413688127006, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.856175972927242 .....iter..... 242\n",
      "\n",
      "Next set of params..... {'max_depth': 15, 'num_leaves': 80, 'min_child_samples': 32, 'scale_pos_weight': 57.56948377357079, 'subsample': 0.8680211851723002, 'colsample_bytree': 0.7973542742495893, 'lambda_2': 3.884695178573244, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.26103116506898155, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8392554991539763 .....iter..... 45\n",
      "\n",
      "Next set of params..... {'max_depth': 23, 'num_leaves': 53, 'min_child_samples': 20, 'scale_pos_weight': 46.99313804146442, 'subsample': 0.9, 'colsample_bytree': 0.668084985251055, 'lambda_2': 4.616591231103718, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.29395750427661427, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8468697123519459 .....iter..... 24\n",
      "\n",
      "Next set of params..... {'max_depth': 5, 'num_leaves': 78, 'min_child_samples': 100, 'scale_pos_weight': 46.107843392144375, 'subsample': 0.6, 'colsample_bytree': 0.6434598179356839, 'lambda_2': 5.364955015561608, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.22265653708101452, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8291032148900169 .....iter..... 368\n",
      "\n",
      "Next set of params..... {'max_depth': 16, 'num_leaves': 6, 'min_child_samples': 200, 'scale_pos_weight': 23.366719502849225, 'subsample': 0.7831531704357252, 'colsample_bytree': 0.6, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.19073979266388708, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8189509306260575 .....iter..... 563\n",
      "\n",
      "Next set of params..... {'max_depth': 23, 'num_leaves': 35, 'min_child_samples': 43, 'scale_pos_weight': 68.40038991600585, 'subsample': 0.6, 'colsample_bytree': 0.6006817019793708, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.21999992148581554, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8299492385786802 .....iter..... 57\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 56, 'min_child_samples': 30, 'scale_pos_weight': 74.45361775295221, 'subsample': 0.7570761274185784, 'colsample_bytree': 0.9, 'lambda_2': 4.607671198802465, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.09986939999821019, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8443316412859561 .....iter..... 101\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 72, 'min_child_samples': 20, 'scale_pos_weight': 17.99454933817572, 'subsample': 0.8779386130669047, 'colsample_bytree': 0.675091429935512, 'lambda_2': 0.2749182680417707, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8510998307952623 .....iter..... 25\n",
      "\n",
      "Next set of params..... {'max_depth': 25, 'num_leaves': 11, 'min_child_samples': 140, 'scale_pos_weight': 1.0, 'subsample': 0.7278733081393106, 'colsample_bytree': 0.6226754859438614, 'lambda_2': 1.1410400927926132, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.12048342321289744, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8443316412859561 .....iter..... 178\n",
      "\n",
      "Next set of params..... {'max_depth': 7, 'num_leaves': 26, 'min_child_samples': 163, 'scale_pos_weight': 1.0, 'subsample': 0.9, 'colsample_bytree': 0.6, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.047534179957369534, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8527918781725888 .....iter..... 399\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 47, 'min_child_samples': 147, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.6679499679387328, 'lambda_2': 5.143061361465749, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.862098138747885 .....iter..... 60\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 55, 'min_child_samples': 105, 'scale_pos_weight': 1.0, 'subsample': 0.783940966802888, 'colsample_bytree': 0.6101446141718955, 'lambda_2': 4.6633239345716575, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2514109978080545, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8654822335025381 .....iter..... 43\n",
      "\n",
      "Next set of params..... {'max_depth': 20, 'num_leaves': 57, 'min_child_samples': 20, 'scale_pos_weight': 98.80457175740068, 'subsample': 0.8006006266506276, 'colsample_bytree': 0.8883226736440919, 'lambda_2': 5.01206527300788, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.2430238667509471, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8527918781725888 .....iter..... 30\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 72, 'min_child_samples': 77, 'scale_pos_weight': 1.0, 'subsample': 0.6, 'colsample_bytree': 0.6982233737366643, 'lambda_2': 1.9958856028627296, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.07855006512112792, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8553299492385786 .....iter..... 116\n",
      "\n",
      "Next set of params..... {'max_depth': 30, 'num_leaves': 80, 'min_child_samples': 129, 'scale_pos_weight': 1.0, 'subsample': 0.694289763059286, 'colsample_bytree': 0.6, 'lambda_2': 6.0, 'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.26444455709504233, 'max_bin': 100}\n",
      "\n",
      "custom SCORE..... 0.8468697123519459 .....iter..... 45\n",
      "CPU times: user 11min 6s, sys: 2min 22s, total: 13min 28s\n",
      "Wall time: 2min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Best score=-0.8663'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "res_gp = gp_minimize(objective, space, n_calls=100, random_state=0,n_random_starts=10)\n",
    "\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8663282571912013\n",
    "# {'max_depth': 26, 'num_leaves': 80, 'min_child_samples': 200, 'scale_pos_weight': 1.0, 'subsample': 0.9, 'colsample_bytree': 0.6, 'lambda_2': 5.785038883822358, 'metric': 'binary_logloss',\n",
    "#  'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', 'learning_rate': 0.3, 'max_bin': 100}\n",
    "\n",
    "# {'max_depth': 19, 'num_leaves': 73, 'min_child_samples': 20, 'scale_pos_weight': 53.59603802481987, \n",
    "#  'subsample': 0.9, 'colsample_bytree': 0.7619369064645131, 'lambda_2': 4.525888999514755, \n",
    "#  'metric': 'binary_logloss', 'nthread': 8, 'boosting_type': 'gbdt', 'objective': 'binary', \n",
    "#  'learning_rate': 0.2850075764695483, 'max_bin': 100}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sub_h2o = aml.leader.predict(h2o.H2OFrame(test_new[X.columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sub_h2o = sub_h2o.as_data_frame()\n",
    "# sub_h2o['id'] = test_new['id'].values\n",
    "# # sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sub_h2o_small = sub_h2o[['id','p1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.15\n",
    "\n",
    "sub['left_label'] = sub['left'].apply(lambda x:int(x>threshold))\n",
    "# sub_h2o_small['left'] = sub_h2o_small['p1'].apply(lambda x:int(x>threshold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_h2o_small['left'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26303854875283444"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['left_label'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ensemble_preds = sub['left']*0.4 + sub_h2o_small['p1']*0.6\n",
    "# ensemble_preds = sub['left']*0.5 + sub_h2o_small['p1']*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ensemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_h2o_small['left'] = ensemble_preds.apply(lambda x:int(x>threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./submissions'):\n",
    "    os.mkdir('./submissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sub_h2o_small['left'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.read_csv('./submissions/submission_baseline_0.1_cutoff_H2OML#3_ensemble.csv')['left'].mean()\n",
    "\n",
    "# Confirms that current run is the benchmark with 0.2789115646258503 target mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub.to_csv('./submissions/submission_baseline_0.15_cutoff_added_support_oppose_sum_fillna.csv',index=False)\n",
    "\n",
    "## oh damn, 0.15 worked well, but is it overfitting leaderboard??? Don't think so yet... lets see!\n",
    "\n",
    "# sub_h2o_small.drop('p1',axis=1).to_csv('./submissions/submission_baseline_0.1_cutoff_H2OML#2.csv',index=False)\n",
    "\n",
    "sub_h2o_small.drop('p1',axis=1).to_csv('./submissions/submission_baseline_0.1_cutoff_H2OML#5_ensemble_50%.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble worked pretty well! reached 84.09\n",
    "\n",
    "okay, so 0.05 is too low cutoff, 0.1 is the optimal, lets stick to that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!! OKAY FILLNA with -9999 didnt work, I mean didnt take us any further, though the score remained almost same, because LGBM takes care of NaNs on it own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
